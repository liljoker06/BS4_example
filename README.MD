# ğŸ“¦ TP Scraping Blog du ModÃ©rateur

Projet rÃ©alisÃ© dans le cadre dâ€™un TP visant Ã  scraper les articles du site [Blog du ModÃ©rateur](https://www.blogdumoderateur.com) Ã  lâ€™aide de **BeautifulSoup4**, stockÃ©s dans **MongoDB**, puis affichÃ©s via une interface frontend en **Next.js**.

---

## ğŸ”§ Technologies utilisÃ©es

### Backend

* Python 3.11
* FastAPI ğŸš€
* Uvicorn
* BeautifulSoup4 ğŸ¥£
* PyMongo / MongoClient
* Docker

### Frontend

* Next.js 15 (App Router)
* TypeScript ğŸ’™
* Axios
* TailwindCSS
* Docker

### Base de donnÃ©es

* MongoDB

---

## ğŸ“‚ Structure du projet

```
â”œâ”€â”€ backend
â”‚   â”œâ”€â”€ app
â”‚   â”‚   â”œâ”€â”€ controllers
â”‚   â”‚   â”œâ”€â”€ models
â”‚   â”‚   â”œâ”€â”€ routes
â”‚   â”‚   â”œâ”€â”€ database.py
â”‚   â”‚   â”œâ”€â”€ main.py
â”‚   â”‚   â”œâ”€â”€ start.py
â”‚   â”‚   â””â”€â”€ init_paths.py
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â””â”€â”€ requirements.txt
â”‚
â”œâ”€â”€ frontend
â”‚   â”œâ”€â”€ public
â”‚   â”œâ”€â”€ src
â”‚   â”‚   â”œâ”€â”€ app
â”‚   â”‚   â”‚   |â”€â”€ import
|   |   |   â””â”€â”€ article
â”‚   â”‚   â”œâ”€â”€ components
â”‚   â”‚   â”œâ”€â”€ context        # ğŸ’¡ Contexte global (React context API)
â”‚   â”‚   â”œâ”€â”€ services       # ğŸ“¡ Appels Axios centralisÃ©s
â”‚   â”‚   â””â”€â”€ types          # ğŸ“ DÃ©clarations TypeScript globales
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”œâ”€â”€ package.json
â”‚   â””â”€â”€ tsconfig.json
â”‚
â”œâ”€â”€ docker-compose.yml
â””â”€â”€ README.md
```

---

## ğŸš€ Lancement du projet (Docker recommandÃ©)

### PrÃ©-requis

* Docker & Docker Compose âœ…
* (facultatif) MongoDB Compass ou autre interface pour visualiser les donnÃ©es

### 1. Cloner le projet

```bash
git clone https://github.com/liljoker06/BS4_example.git
cd tp-scraping-blogduweb
```

### 2. Lancer les services

```bash
docker-compose up --build
```

Cela dÃ©marre :

* Le backend FastAPI ([http://localhost:8000](http://localhost:8000))
* Le frontend Next.js ([http://localhost:3000](http://localhost:3000))

### 3. AccÃ¨s Ã  lâ€™interface

* Visitez `http://localhost:3000`
* Cliquez sur **Importer un article** pour lancer un scraping âœ¨

---

## ğŸ§ª Mode dÃ©veloppement manuel (sans Docker)

### Backend (FastAPI)

```bash
cd backend
pip install -r requirements.txt
python app/start.py
```

### Frontend (Next.js)

```bash
cd frontend
npm install
npm run dev
```

---

## ğŸ—ƒï¸ AccÃ¨s Ã  la base de donnÃ©es MongoDB

* Adresse : `mongodb://localhost:27017`
* Base utilisÃ©e : `bdm`
* Collections : `articles`

Utilisez MongoDB Compass pour visualiser les documents.

---

## ğŸ› RÃ©solution de problÃ¨mes courants

### ProblÃ¨me `ERR_EMPTY_RESPONSE`

Assurez-vous que :

* Le backend FastAPI tourne sans erreur
* Le `NEXT_PUBLIC_API_URL` est bien configurÃ© (ex: `http://localhost:8000`)

### Erreur `Could not find .next build`

Le build frontend a Ã©chouÃ©. Corrigez les erreurs TypeScript/ESLint ou exÃ©cutez :

```bash
npm run build
```

---

## ğŸ§¼ .gitignore recommandÃ©

### Backend (`backend/.gitignore`)

```
__pycache__/
*.pyc
.env
*.log
```

### Frontend (`frontend/.gitignore`)

```
.next/
node_modules/
dist/
.env.local
```

---

## ğŸ’¡ Bonus : MongoDB local sous Windows

```bash
net start MongoDB
```

Ou utilisez MongoDB Compass

---

## âœï¸ Auteur

> Ce projet a Ã©tÃ© rÃ©alisÃ© dans le cadre du TP Â«Â Scraping & Web DataÂ Â» â€“ 2025

---

## ğŸ«¶ Merci !

Nâ€™hÃ©sitez pas Ã  forker, tester, amÃ©liorer ce projet. Bon scraping !
